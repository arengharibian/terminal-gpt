_____                   _             _            ____ ____ _____ 
|_   _|__ _ __ _ __ ___ (_)_ __   __ _| |          / ___|  _ \_   _|
  | |/ _ \ '__| '_ ` _ \| | '_ \ / _` | |  _____  | |  _| |_) || |  
  | |  __/ |  | | | | | | | | | | (_| | | |_____| | |_| |  __/ | |  
  |_|\___|_|  |_| |_| |_|_|_| |_|\__,_|_|          \____|_|    |_|  


=============================
 Terminal GPT - TARS Edition
=============================

A terminal chat app powered by Ollama with TARS personality
from Interstellar. Helpful answers with dry wit and sarcasm.
No API keys. Runs locally.


------------------------------------------------------------
1. Install Dependencies
------------------------------------------------------------

    cd terminal-gpt
    python3 -m venv .venv

Activate:

    Mac/Linux:    source .venv/bin/activate
    Windows:      .venv\Scripts\activate

Install packages:

    pip install requests fastapi uvicorn pydantic


------------------------------------------------------------
2. Install Ollama
------------------------------------------------------------

Download from: https://ollama.com

Mac (Homebrew):

    brew install --cask ollama


-------------------------------------------------------------
3. Pull a Model
-------------------------------------------------------------

    ollama pull llama3.2

Make sure MODEL in terminal_gpt.py matches your model.


------------------------------------------------------------
4. Run the App
------------------------------------------------------------

CLI mode:

    python3 terminal_gpt.py

Web mode:

    uvicorn web_server:app --reload

Then open: http://127.0.0.1:8000

Example:

    > hello
    TARS: Oh good, another human. What do you need?

    > what is python
    TARS: A programming language. Also a snake. I assume
    you mean the former unless your questions are about
    to get much more interesting.


------------------------------------------------------------
5. One-Shot Mode
------------------------------------------------------------

    python3 terminal_gpt.py "explain what BFS is"


------------------------------------------------------------
6. Exit
------------------------------------------------------------

CLI: type 'exit' or 'quit' or press Ctrl+C
Web: just close the browser tab


------------------------------------------------------------
7. Common Issues
------------------------------------------------------------

"requests not found"
    pip install requests

"Connection refused"
    Ollama isn't running. Open the Ollama app.

"model not found"
    ollama pull llama3.2

Empty responses
    Try a different model or restart Ollama.


------------------------------------------------------------
8. Change the Model
------------------------------------------------------------

In terminal_gpt.py:

    MODEL = "llama3.2"

Other options:

    MODEL = "llama3.1"
    MODEL = "mistral"
    MODEL = "phi3"


------------------------------------------------------------
You're All Set!
------------------------------------------------------------

No API keys. Everything local.

TARS: Congratulations. You read documentation.
      That puts you ahead of 90% of humans.